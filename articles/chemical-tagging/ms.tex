%% This document is part of the snob project
%% Copyright 2017 the authors. All rights reserved.

\documentclass{aastex61}

\usepackage{bm}

% For revision history
\IfFileExists{vc.tex}{\input{vc.tex}}{
    \newcommand{\githash}{UNKNOWN}
    \newcommand{\giturl}{UNKNOWN}}

% Define commands
\newcommand{\article}{\emph{Article}}
\newcommand{\acronym}[1]{{\small{#1}}}
\newcommand{\project}[1]{\textsl{#1}}

% Have some maaaath.
\def\infinity{\rotatebox{90}{8}}

% Affiliation(s)
\newcommand{\moca}{
	\affil{School of Physics and Astronomy, Monash University, 
		   Melbourne, Clayton VIC 3800, Australia}}
\newcommand{\claytonfit}{
	\affil{Faculty of Information Technology, Monash University,
	       Melbourne, Clayton VIC 3800, Australia}}
\newcommand{\caulfieldfit}{
	\affil{Faculty of Information Technology, Monash University,
		   Melbourne, Caulfield East VIC 3145, Australia}}



\received{}
\revised{}
\accepted{}

\submitjournal{TBD} % ApJ, MNRAS, PASA?

\shorttitle{Chemical Tagging Using Minimum Message Length}
\shortauthors{Casey et al.}

\begin{document}

\title{Chemical Tagging Using Minimum Message Length}

\correspondingauthor{Andrew R. Casey}
\email{andrew.casey@monash.edu}

\author[0000-0003-0174-0564]{Andrew R. Casey}
\moca
\claytonfit

\author{(some order of:}

\author[0000-0003-2952-859X]{John Lattanzio}
\moca

\author[0000-0002-0583-5918]{David Dowe} 
\claytonfit

\author[0000-0002-1716-690X]{Aldeida Aleti}
\caulfieldfit

\author{)}

\author{others?}
 
\begin{abstract}
Chemical tagging seeks to identify co-natal stars by their present-day 
photospheric abundances, long after their phase space similarity is lost.
In principle the detailed chemical abundances of a transformative number of
stars could be used to reconstruct the evolution of the Milky Way, providing
insight on supernovae yields, galactic dynamics (e.g., constraints on radial 
mixing), the initial mass function, as well as the formation and destruction
of star clusters. Some progress has been made towards chemical tagging, but 
here we argue that even the \emph{extent} of the problem has not been realised.
We introduce the Real World problems associated with chemical tagging at scale,
and describe how currently considered methods will inevitably fail even under
the most unrealistically optimistic conditions. We introduce the minimum message
length to the astronomical community as a promising alternative to chemical
tagging, one which has the capability to address all ensivaged problems with
chemical tagging simultaneously. We perform chemical tagging experiments with
infinte Gaussian mixture models, and demonstrate using real and generated data 
that MML outperforms all other considered penalty techniques. 
\end{abstract}

\keywords{}

\section{Introduction} 
\label{sec:introduction}

\citet{Freeman_2002} introduced chemical tagging as an idea to identify groups 
of stars that formed together in the same gas cloud, which are no longer
identifiable in phase space, either by their physical location or orbital
dynamics.  This idea is attractive because the observable chemical abundances of 
stars remains largely unchanged throughout a star's lifetime, whereas phase 
space information is quickly damped through dynamical interactions. Moreover, 
while most stars are thought to form in star clusters \citep{someone}, only the
most massive or isolated star clusters are able to survive the star formation
process \citep{someone2}. For this reason we rely on `field' stars -- that is,
stars that are not clearly associated with a known star cluster -- in order to
infer the formation of the Milky Way.


Some progress has been made towards chemical tagging in simplistic experiments, 
but the full extent of chemical tagging has yet to be realised. Indeed, in this 
\article\ we assert that even \emph{the full extent of the problem} of chemical 
tagging has yet to be realised. 
% Some other comments about this?

\subsection*{A Probabilistic Approach to Chemical Tagging}
\ref{section:the-problem}


What is needed to make things work? We outline the 12 disciples:

\begin{enumerate}
\item The number of clusters.
\item The number of latent factors (e.g., supernovae yields, AGB yields).
\item The multivariate factor loads of individual latent factors.
\item The relative weighting (yet another latent factor, which is however not
      common between all mixtures) of individual mixtures.
\item The relative \emph{scoring} of different latent factors on each star.
\item The intrinsic \emph{specific variances} of the individual abundances.
\item The multivariate mean abundances and covariance matrices of each star
      cluster, where the covariance matrix includes off-diagonal terms that
      describe the \emph{data} correlations (e.g., the correlations that result
      from trying to measure multiple abundances from the same data).
\item Atomic diffusion, veiling, and thermohaline mixing: The surface chemical
      abundances of stars \emph{will change} over its lifetime.
\item Probabilistic priors (perhaps very hard priors) on joint responsibilities
      of stars that are specified from astrometric constraints.
\item There are missing data. Accept it.
\item There are \emph{upper limits} on some data.\footnote{
        Spectroscopists are probably the worst in the Universe when it comes to
        reporting upper limits. They will report an `\emph{upper limit}', when
        what might mean is the \emph{absolute limit} where there is zero
        likelihood that the true value is above the given point estimate (which might as well be $+\infinity$, or
        they may describe a \emph{pseudo-1$\sigma$} limit which is estimated
        from the locally (yet covariant!) heteroskedastic noise in the data (which often might as well be $\approx$0).
        In reality, an upper limit ought to be given as a probability density
        function that is skewed in one direction, perhaps similar to the shape
        of a log-normal distribution. In any case, the confidence to which they
        describe their `\emph{upper limit}' ought to be given.}
\item There are correlations in the measurements that result from trying to
      measure two (or more) abundances from the same data. As an example,
      consider a rare -- yet important -- chemical abundance that has a single
      atomic absorption line which is blended with a more common elemental
      abundance. In all likelihood, there will be a strong positive correlation
      between the abundance derived between the rare and more common elemental
      abundance.
\end{enumerate}


% What work has been done on chemical tagging?

% Unfortunately these approaches have only sought to solve individual problems
% within chemical tagging. Doing so -- and then later using those results to
% infer something else about the galaxy -- makes both results inconsistent,
% both statistically, and otherwise.



In Section \ref{sec:model} we introduce a simplistic approach to chemical
tagging that relies on probabilistically modelling stellar chemical abundances
as a mixture of (potentially infinite) multivariate Gaussian distributions.

There we introduce the concept of MML,


\section{The Model}
\ref{sec:the-model}

Here we introduce a simple probablistic approach to chemical tagging, and in
later sections we will formulate the objective function for MML. Our approach is
the simplistic in the sense that we will ignore many of the aforementioned
problems that will plague chemical tagging at scale. Specifically we make the
following assumptions:

\begin{itemize}
\item We assume that the data (e.g., the detailed chemical abundances of stars)
      can be represented by a mixture of multivariate Gaussian distributions.
\item We will assume that the number of \emph{true} multivariate Gaussian
      distributions is not known. This assumption applies to our experiements
      involving generated data, and those using real data.
\item In addition to not knowing the \emph{number} of multivariate normal
      distributions, we further assume that the means and covariance matrices of
      each mixture is unknown.
\item Here we assume that the covariance matrix of individual components can be
      described as `free` or `full', in the sense that the data within a cluster
      can have off-diagonal correlation terms, which are unknown.
\item In all experiments we will assume that the data have homoskedastic noise
      properties.
\item The relative weights (or mixing proportions) of different distributions
      is unknown. We further will assume a relative (or conditional)
      probability distribution for each star belonging to a given cluster. That
      is to say, we do not adopt a `\emph{hard selection}' approach to cluster
      modelling, where stars would be assigned as definitively belonging to one
      cluster or another.
      % TODO: should we actually introduce the partial assignment later when we 
      % talk about the Gaussian distributions?
\end{itemize}

We have made relatively few explicit assumptions about the model for the data,
but even the model described constitutes a very formidable model selection 
problem. The reason is because we do not know \emph{how many} multivariate
Gaussian distributions we ought to chose to fit the data. Including more
mixtures will consistently provide a better fit to the data (in a likelihood
sense), but we must make some decision or heuristic as to whether the additional
mixture is justified.

The probability density function $f$ for a multivariate normal distribution with
$d$ dimensions is given by

\begin{equation}
    f(y_n|\bm{\mu},\bm{\Sigma}) 
        = \frac{1}{\sqrt{(2\pi)^d|\bm{\Sigma}|}}
          \exp{\left[-\frac{1}{2}(\bm{y} - \bm{\mu})^\intercal\bm{\Sigma}^{-1}(\bm{y} - \bm{\mu})\right]}
\end{equation}

\noindent{}where $\bm{\mu}$ and $\bm{\Sigma}$ is the multivariate mean and 
covariance matrix, and $\bm{y}$ are the data.  When modelling a mixture of
Gaussians, there are two approaches in determining assignments (or
responsibilities) of each star to a given cluster. One approach is to include
a (discrete) model parameter for every data point, which represents the index
of the mixture that the observation is assigned to. The second approach is to 
use a weighted mixture. These two are mathematically identical.
% TODO


\begin{equation}
% TODO
\end{equation}


\section{Introducing MML}
% MML formalism


\subsection{Prior probabilities on the parameters}


We assume a uniform prior on the mixing weights $\bm{w}$, only requiring that
their summation equals one. We adopt a wide uniform prior of $\mathcal{U}(\bm{\mu}) = [-12, 12]$ on all
multivariate mean abundances $\bm{\mu}$ (in all $d$ dimensions). This prior
is sufficiently wide that it has no impact on our inferences (24 orders of
magnitude!), but remains proper. We adopt a congujate inverted Wishart prior 
for the covariance matrices in the individual mixtures. Ignoring the effect of 
our prior on $\bm{\mu}$ gives us a proportional joint prior,

\begin{equation}
    p(\bm{\mu},\bm{\Sigma}) \propto |C|^{\frac{d + 1}{2}} 
\end{equation}
% TODO: DERIVE THIS.



\acknowledgments
Who?
Grants.

\software{astropy \citep{Robitaille:2013}, numpy, scipy, scikit-learn} 

\begin{thebibliography}{}

\bibitem[Astropy Collaboration et al.(2013)]{Robitaille:2013} Astropy Collaboration, Robitaille, T.~P., Tollerud, E.~J., et al.\ 2013, \aap, 558, A33 

\end{thebibliography}


\end{document}
