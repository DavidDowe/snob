%% This document is part of the snob project
%% Copyright 2017 the authors. All rights reserved.

\documentclass{aastex61}

\usepackage{bm}
\usepackage{verbatim} % for \begin{comment}'ing out sections.

% For revision history
\IfFileExists{vc.tex}{\input{vc.tex}}{
    \newcommand{\githash}{UNKNOWN}
    \newcommand{\giturl}{UNKNOWN}}

% Define commands
\newcommand{\article}{\emph{Article}}
\newcommand{\acronym}[1]{{\small{#1}}}
\newcommand{\project}[1]{\textsl{#1}}

% Surveys
\newcommand{\apogee}{\acronym{APOGEE}}
\newcommand{\ges}{\acronym{GES}}
\newcommand{\hermes}{\acronym{HERMES}}
\newcommand{\galah}{\acronym{GALAH}}
\newcommand{\fourmost}{\acronym{4MOST}}
\newcommand{\weave}{\acronym{WEAVE}}
\newcommand{\gaia}{\project{Gaia}}

% Common terms
\def\teff{T_{\rm eff}}
\def\logg{\log{g}}

% Have some maaaath.
\def\infinity{\rotatebox{90}{8}}

% Affiliation(s)
\newcommand{\moca}{
	\affil{School of Physics and Astronomy, Monash University, 
		   Melbourne, Clayton VIC 3800, Australia}}
\newcommand{\claytonfit}{
	\affil{Faculty of Information Technology, Monash University,
	       Melbourne, Clayton VIC 3800, Australia}}
\newcommand{\caulfieldfit}{
	\affil{Faculty of Information Technology, Monash University,
		   Melbourne, Caulfield East VIC 3145, Australia}}



\received{}
\revised{}
\accepted{}

\submitjournal{TBD} % ApJ, MNRAS, PASA?

\shorttitle{Chemical Tagging Using Minimum Message Length. I.}
\shortauthors{Casey et al.}

\begin{document}

\title{Chemical Tagging Using Minimum Message Length. I.\\
       Gaussian Mixture Modelling}

\correspondingauthor{Andrew R. Casey}
\email{andrew.casey@monash.edu}

\author[0000-0003-0174-0564]{Andrew R. Casey}
\moca
\claytonfit

\author{(some order of:}

\author[0000-0003-2952-859X]{John Lattanzio}
\moca

\author[0000-0002-0583-5918]{David Dowe} 
\claytonfit

\author[0000-0002-1716-690X]{Aldeida Aleti}
\caulfieldfit

\author{)}

\author{others?}
 
\begin{abstract}
Chemical tagging seeks to identify co-natal stars by their present-day 
photospheric abundances, long after their phase space similarity is lost.
In principle the detailed chemical abundances of a transformative number of
stars could be used to reconstruct the evolution of the Milky Way, providing
insight on supernovae yields, galactic dynamics (e.g., constraints on radial 
mixing), the initial mass function, as well as the formation and destruction
of star clusters. Some progress has been made towards chemical tagging, but 
here we argue that even the \emph{extent} of the problem has not been realised.
We introduce the Real World problems associated with chemical tagging at scale,
and describe how currently considered methods will inevitably fail even under
the most unrealistically optimistic conditions. We introduce the minimum message
length to the astronomical community as a promising alternative to chemical
tagging, one which has the capability to address all ensivaged problems with
chemical tagging simultaneously. We perform chemical tagging experiments with
infinte Gaussian mixture models, and demonstrate using real and generated data 
that MML outperforms all other considered penalty techniques. 
\end{abstract}

\keywords{}

\section{Introduction} 
\label{sec:introduction}

\citet{Freeman_2002} introduced the idea of chemical tagging to identify 
groups of stars that formed together in the same gas cloud, which are no 
longer identifiable from their physical proximity or orbital properties.
This idea is attractive because the observable chemical abundances of 
stars remains largely unchanged throughout a star's lifetime, whereas phase 
space similarity can be quickly washed out through dynamical interactions. 
Indeed, although most stars are thought to form in clusters \citep{someone},
only the most massive or isolated star clusters are able to survive the star
formation process \citep{someone2}, leaving most clusters to become 
dynamically unbound after about 1~Gyr. 

%Their signature of formation is locked up in their detailed chemical fingerprint



%The Milky Way is our best laboratory for understanding galaxy formation and
%evolution. 
Making strong inferences about the Milky Way's formation and evolution from
chemical tagging will require a transformative number of stars with precise
abundances.
Ground- and space-based surveys are poised to deliver those data this decade. 
The Apache Point Observatory Galactic Evolution Experiment 
\citep[\apogee, e.g.,][]{apogee} and the Gaia-ESO survey 
\citep[\ges;][]{Gilmore_2012,Randich_2013} are already delivering $10^5$ stars 
with 20--40 precise abundances, and the Galactic Archaeology with \hermes\ 
\citep[\galah;][]{DeSilva_2015} survey seeks to derive $\approx$30 precise 
abundances for $\sim10^6$ stars. 
Future ground-based surveys will derive abundances from $\approx$20 million 
spectra in each hemisphere \citep[e.g., \weave, \fourmost;][]{weave,4most},
and the radial velocity spectrometer on \gaia\ can deliver a few abundances 
for $\approx$150 million stars.


Chemical tagging is a simple idea, but with this volume of data it represents
a formidable parameter estimation and model selection problem.
Before reviewing the literature on chemical tagging, here we explicitly
formulate the scope of the analysis problem.


\subsection{What do we want to infer from chemical abundances?}
\label{sec:the-problem}


Let us assume that a set of stars have been observed spectroscopically, and
chemical abundances have been derived from those data.
We will unrealistically assume that the data are noiseless, and the derived
abundances are unbiased, known with infinite precision, and complete (e.g., no 
missing abundances).
Regardless of the number of stars observed or abundances derived, there are a
number of inferences we seek to make:


\begin{enumerate}
  \item The number of star clusters (or star-forming events) where at least 
        one star was observed and chemical abundances were derived.
  \item The conditional probabilities (or memberships) of each star belonging
        to every star cluster or star-forming event.
        Alternatively, the relative weighting of individual mixtures.
  \item The mean abundances of each star cluster. 
  \item The covariance matrix of abundances of each star cluster.
        This covariance matrix includes the intrinsic (cluster) variance
        of individual abundances (e.g., the homogeniety), and allows for
        correlations between abundances.\footnote{
          It is likely -- or hoped -- that \emph{true} correlations between 
          abundances will be accounted for through the latent factors, and any 
          remaining correlations are the result of the measurements.}
  \item The \emph{number} of common multivariate latent factors, variables 
        that are not observable but affect all or many of the observations.
        In the context of chemical tagging, the yields of core-collapse
        supernovae can be considered a common multivariate latent factor: 
        those yields are not directly observable, but they contribute to much 
        of the data.
        Here we are interested in the \emph{number} of common multivariate
        latent factors. For example, the number of sources of enrichment:
        different classes of supernovae, asymptotic giant branch (AGB) stars, 
        etc.
  \item The multivariate factor loads of individual latent factors. 
        For example, if core-collapse supernovae and AGB stars had both 
        contributed to the chemical abundances of all stars in the sample, 
        then the \emph{factor loads} would be the \emph{yield} of the 
        supernovae, or the yield of relative abundances that were produced by 
        the AGB star. 
        Each star will be affected differently by those yields (see item 7).
  \item The relative \emph{scoring} of different latent factors on each star.
        This is a scaling that is applied to the latent yields. Continuing our
        analogy on yields from core-collapse supernovae and AGB stars, the
        \emph{factor scores} can be thought of as the relative contributions 
        of the different factor loads, for a single star.
  \item The intrinsic \emph{specific variances} of the individual abundances.
        These variances can be thought of as the intrinsic variability from 
        the different factor loads.
        The intrisic variances affect all observations, before accounting for
        any homogeneity in individual clusters.
  \item The \emph{number} of stellar age- or parameter-dependent latent 
        factors that affect the data. 
        The surface chemical abundances of stars \emph{do change} over its
        lifetime, at least in part due to atomic diffusion, veiling, and 
        thermohaling mixing.
        Understanding and modelling these effects will be critical for 
        chemical tagging stars across all stellar ages and evolutionary states.
  \item The factor loads of stellar age- or parameter-dependent latent factors.
        In this example, a single multivariate factor load may represent the
        age-dependent effects of atomic diffusion.
  \item The factor scores of stellar age- or parameter-dependent latent 
        factors.
\end{enumerate}


The number of things we seek to infer from the available chemical abundances
is vast.
Indeed, even if we ignore the latent factors then a non-trivial model
selection problem remains: What is the number of star clusters or star-forming 
events?
In the full description of chemical tagging we seek to know (1) the number of
star clusters, (2) the number of latent factors, and (3) the number of age-
or stellar parameter-dependent factors.
Going further, if we wanted to improve the accuracy and precision of our
solution then we may seek to include joint priors on the memberships of stars
being associated with specific clusters, either based on their ages or
astrometry.
In summary, simplified versions of chemical tagging represent formidable model
selection problems with non-convex\footnote{
  If a problem is convex then any local solution is mathematically guaranteed
  to be the global solution.
  If the problem is non-convex, then a local solution may not be the global
  solution.
} objective functions.


\subsection{Chemical tagging progress to date}
\label{sec:literature-review}


There has been substantial progress on chemical tagging in the last decade.
Given the difficulty of the problem, most studies have opted to address one
(or a few) of the challenges listed in Section~\ref{sec:the-problem}. 
The most common issue addressed is group-finding (items 1-4). 
Some works have sought to construct a similarity metric \citep{Mitschang}
based on chemical abundances of undisrupted clusters. 
Others have applied group-finding algorithms \citep{Hogg,Gregor}.

- Dimensionality of chemical abundance space.

- Chemical homogeneity.

- Dopplegangers.


The aforementioned chemical tagging experiments have sought to address only 
individual challenges associated with chemical tagging.
These challenges are all related, and therefore addressing them separately
will yield results that are not self-consistent, and do not make use of all
the information available.


In this \article\ we will introduce a simple probabilistic approach to
chemical tagging, where the data are modelled as a mixture of multivariate
Gaussian distributions and the number of mixtures is unknown (Section 
\ref{sec:the-model}). 
In Section \ref{sec:mml} we introduce the principle of minimum message length
(MML) and formulate our objective function.
Although our model is simplistic in the sense that we will only address some
aspects of chemical tagging, in Section \ref{sec:experiments} our experiments
show that our MML-based approach is superior to all other methods considered 
for chemical tagging.
In Section \ref{sec:discussion} we describe how the MML principle can be used
to construct a fully consistent probabilistic approach to chemical tagging,
and simultaneously address the challenges outlined in Section 
\ref{sec:the-problem}.



\section{The Model}
\label{sec:the-model}

We make the following explicit assumptions:

\begin{itemize}
\item We assume that the data (e.g., the $D$ detailed chemical abundances of 
      $N$ stars) can be represented by a mixture of $K$ multivariate Gaussian
      distributions.
\item We assume that there are no missing data values. For example, if a star
      has been observed, then there is a complete set of $D$ chemical 
      abundances available.
\item We will assume that the number of \emph{true} multivariate Gaussian
      distributions $K_{true}$ is not known. This assumption applies to our 
      experiements involving generated data, and those using real data.
\item In addition to not knowing the \emph{number} of multivariate normal
      distributions, we further assume that the means $\bm{\mu}$ and 
      covariance matrices $\bm{C}$ of each $K$th mixture is unknown.
\item We assume that the covariance matrix of individual components can be
      described as `free' or `full', insomuch that the data within a cluster
      can have off-diagonal correlation terms, and those terms are unknown.
\item In all experiments we will assume that the data have homoskedastic noise
      properties.
\item The relative weights $\bm{w}$ (or mixing proportions) of $K$ 
      distributions is unknown. 
\item We assume a relative (or conditional) probability distribution for each 
      star belonging to a given cluster. That is to say that we do not adopt a 
      `\emph{hard selection}' approach to cluster modelling, where stars would
      be assigned as definitively belonging to one cluster or another. Our
      approach could be described as `\emph{soft} clustering'. This assumption
      has practical numerical outcomes and implications for the message length.
\end{itemize}

We have made relatively few explicit assumptions about the model for the data,
but even the model described constitutes a very formidable model selection 
problem. This is because we do not know \emph{how many} multivariate Gaussian
distributions we ought to chose to fit the data. Including more mixtures will
consistently provide a better fit to the data (in a likelihood sense), but we 
must make some decision or heuristic as to whether the additional mixture is 
justified.

The probability density function $f$ for a multivariate normal distribution 
with $d$ dimensions is given by

\begin{equation}
    f(\bm{y}|\bm{\mu},\bm{\Sigma}) 
        = \frac{1}{\sqrt{(2\pi)^d|\bm{\Sigma}|}}
          \exp{\left[-\frac{1}{2}(\bm{y} - \bm{\mu})^\intercal\bm{\Sigma}^{-1}(\bm{y} - \bm{\mu})\right]}
\end{equation}

\noindent{}where $\bm{\mu}$ and $\bm{\Sigma}$ is the multivariate mean and 
covariance matrix, and $\bm{y}$ are the data.  

% Full probability for the data.


When modelling a mixture of
Gaussians, there are two approaches in determining assignments (or
responsibilities) of each star to a given cluster. One approach is to include
a (discrete) model parameter for every data point, which represents the index
of the mixture that the observation is assigned to. The second approach is to 
use a weighted mixture. These two are mathematically identical.
% TODO


\begin{equation}
% TODO
\end{equation}


\subsection{Minimum Message Length}
\label{sec:mml}

Background to MML, etc.

We want to minimize the message length.

Link to Bayesian evidence, other things, etc.

In order to minimize the full message length, we must specify the priors on
our parameters.


\subsection{Prior probabilities on the parameters}


We assume a uniform prior on the mixing weights $\bm{w}$, only requiring that
$\sum_{k=1}^{K}w_k = 1$. A useful extension of this work might be to impose
a Dirchlet prior on the mixing weights $\bm{w}$, or a distribution inspired by
the stellar mass function and observed selection function.


We adopt an improper uniform prior of 
$\mathcal{U}(\bm{\mu}) = [-\infinity, \infinity]$ on all multivariate mean 
abundances $\bm{\mu}$ (in all $D$ dimensions). This prior has no impact on
our inferences and becomes proper when it enters the (accepted) posterior
distribution. We similarily could adopt a proper and large uniform prior on all 
mean abundances of $\mathcal{U}(\bm{\mu}) = [-12, 12]$ and the result would be
the same.

We adopt a congujate inverted Wishart prior for the covariance matrices in the
individual mixtures. The joint prior density for the parameters of a single
mixture is given by the limiting form of the normal inverted-Wishart
density \citep[e.g., Section 5.2.3 of ][]{Schafer_1990}:


\begin{equation}
    p(\bm{\mu},\bm{\Sigma}) \propto |C|^{\frac{d + 1}{2}} \quad .
\end{equation}



\subsection{Expected Fisher information}

Computing the expected Fisher information requires the second order partial
derivatives of the negative log-likelihood $-\mathcal{L}(\bm{y}|\bm{\mu},\bm{\Sigma})$.
This can be tricky for mixtures -- explain why.
We approximate the determinant of of the Fisher information matrix,
$|\mathcal{F}(\bm{\mu},\bm{\Sigma})|$ as the product of $|\mathcal{F}\left(\bm{\mu}\right)|$ and $|\mathcal{F}\left(\bm{\Sigma}\right)|$ \citep{Oliver_1996,Roberts_1998}.

% Equation for log-likelihood of the data:
% \begin{equation}
% \mathcal{L}\left(\bm{y}|\bm{\mu},\bm{\Sigma}) = -\frac{Nd}{2}\log{\left(2\pi\right)} - \frac{N}{2}\log{|\bm{\Sigma}|} - \frac{1}{2}\Sigma_{i=1}^{N}(\bm{y}_i - \bm{mu})^\intercal{}\Sigma^{-1}(\bm{y}_i - \bm{\mu})
%\end{equation}

Taking the second derivative of the log-likelihood of the data with respect to $\bm{\mu}$:

\begin{equation}
\frac{\delta\mathcal{L}}{\delta\bm{\mu}} = \Sigma_{i=1}^{N}\bm{C}^{-1}(\bm{y}_i - \bm{\mu})
\end{equation}

\begin{equation}
\frac{\delta^2\mathcal{L}}{\delta\bm{\mu}^2} = N\bm{C}^{-1}
\end{equation}


Computing the Fisher information of the covariance matrix $|\mathcal{F}\left(\bm{C}\right)|$ is harder. For a full covariance matrix with off-diagonal terms, the total
number of free parameters required is $d(d+1)/2$.
\citep{Magnus_1988} derived an analytical expression:
% Dwyer_1967, Bozdogan_1990? Drton_2009?
% TODO: This derivation is a nightmare to find


\begin{equation}
|\mathcal{F}\left(\bm{C}\right) = N^\frac{d(d+1)}{2}2^{-d}|\bm{C}|^{-(d+1)}
\end{equation}

Giving the approximate determinant of the Fisher information $|\mathcal{F}\left(\bm{\mu},\bm{C}\right)|$ as:

\begin{eqnarray}
  |\mathcal{F}\left(\bm{\mu},\bm{C}\right)| & \approx & |\mathcal{F}\left(\bm{\mu}\right)|\cdot|\mathcal{F}\left(\bm{C}\right)| \\
  & \approx & N^{d}|\bm{C}|^{-1}N^\frac{d(d+1)}{2}2^{-d}|\bm{C}|^{-(d+1)} \\
  |\mathcal{F}\left(\bm{\mu},\bm{C}\right)| & \approx & N^\frac{d(d+3)}{2}2^{-d}|\bm{C}|^{-(d+2)}
\end{eqnarray}





A common method to estimate the parameters of a Gaussian distribution is by
maximum likelihood, where the log-likelihood $\mathcal{L}$ is maximized. In
order to do this, one computes the gradient of the log-likelihood function
with respect to the parameters and solves the resulting equations.


- Encoding the message.


- Process of expectation and maximization for each step.


\section{Experiments}
\label{sec:experiments}

Here we describe simple chemical tagging experiments that are so optimistic
that they could be considered laughable, but ones which will still fail for
even the most simplistic chemical tagging approaches.

Each experiment will edge closer to a representative example of chemical
tagging.

\subsection{Experiment 0: Position and Velocity information}

\subsection{Experiment 1: Using clusters, full complement of chemical abundances}

\subsection{Experiment 2: Using all clusters, full complement of chemical abundances, random fractions of field stars}

\subsection{Experiment 3: Using clusters, limited set of chemical abundances}

\subsection{Experiment 4: Fake data to replicate clusters, but use latent factor}

\subsection{Experiment 5: Fake data to replicate clusters, but use multiple latent factors}


\section{Discussion}
\label{sec:discussion}


\acknowledgments

This research is supported by an Australian Research Council Discovery Project
grant (DP160100637). 
Source code for this project is available at \texttt{\giturl}. This document
was compiled on \gitdate\ from revision hash \texttt{\githash} in that
repository. 


\software{astropy \citep{Robitaille:2013}, numpy, scipy, scikit-learn} 

\begin{thebibliography}{}

% Note: I include the DOI as a comment on the same line after every \bibitem
%       entry. I do this in case I ever need to extract full bibstems for the
%       bibliography, which can be done using this curl command and the DOI:

%       curl -LH "Accept: application/x-bibtex" http://dx.doi.org/10.5555/12345678 

%       If no DOI is available then I list the ADS identifier.

\bibitem[Astropy Collaboration et al.(2013)]{Robitaille:2013} Astropy Collaboration, Robitaille, T.~P., Tollerud, E.~J., et al.\ 2013, \aap, 558, A33 % 10.1051/0004-6361/201322068

\bibitem[Dalton et al.(2012)]{weave} Dalton, G., Trager, S.~C., Abrams, D.~C., et al.\ 2012, \procspie, 8446, 84460P % 10.1117/12.925950

\bibitem[de Jong et al.(2012)]{4most} de Jong, R.~S., Bellido-Tirado, O., Chiappini, C., et al.\ 2012, \procspie, 8446, 84460T % 10.1117/12.926239

\bibitem[De Silva et al.(2015)]{DeSilva_2015} De Silva, G.~M., Freeman, K.~C., Bland-Hawthorn, J., et al.\ 2015, \mnras, 449, 2604 % 10.1093/mnras/stv327

\bibitem[Freeman \& Bland-Hawthorn(2002)]{Freeman_2002} Freeman, K., \& Bland-Hawthorn, J.\ 2002, \araa, 40, 487 % 10.1146/annurev.astro.40.060401.093840

\bibitem[Gilmore et al.(2012)]{Gilmore_2012} Gilmore, G., Randich, S., Asplund, M., et al.\ 2012, The Messenger, 147, 25 % 2012Msngr.147...25G

\bibitem[Majewski et al.(2015)]{apogee} Majewski, S.~R., Schiavon, R.~P., Frinchaboy, P.~M., et al.\ 2015, arXiv:1509.05420 % 2015arXiv150905420M

\bibitem[Randich et al.(2013)]{Randich_2013} Randich, S., Gilmore, G., \& Gaia-ESO Consortium 2013, The Messenger, 154, 47 % 2013Msngr.154...47R

\bibitem[Schafer (1997)]{Schafer_1997} Schafer, J.~L., 1997, Analysis of Incomplete Multivariate Data (CRC Press) % 10.1002/(SICI)1097-0258(20000415)19:7<1006::AID-SIM384>3.0.CO;2-T

\end{thebibliography}

\end{document}






\begin{comment}
\subsection{Problems using real world data}

There are a number of problems to consider when using real world data.

\begin{enumerate}
  \item There are missing data.
        Given high-resolution spectra with signal-to-noise (S/N) ratios of
        $\infinity$, there will be chemical abundances where only an upper
        limit can be reported.
        For example, if there are no transitions in the spectra, or the
        chemical abundance is so low that there is no net absorption in the 
        photosphere, then there will be no observable effect in the data.
        Chemical tagging approaches must be able to accept `upper limits'\footnote{
          The use of the term `\emph{upper limit}' amongst spectroscopists is
          muddled. 
          Frequently an `upper limit' is reported that represents (near-)zero
          likelihood that the abundance could be above the quoted value.
          Alternatively, a reported `upper limit' might describe a 
          $\approx1\sigma$ (non-symmetric) limit estimated from the local
          noise in the data.
          Ideally a posterior distribution should to be provided.
        }
        reported by spectroscopists.
  \item The abundance measurements may be biased.
  \item If there are uncertainties provided for abundances, then those
        uncertainties are likely to be underestimated.
  \item The measurements will have heteroscedastic noise properties.
        In other words, the abundance uncertainties will differ between
        elements and stars.
  \item The measurements of individual chemical abundances may be correlated
        due to the way the abundance was measured.
        For example, if there is a single absorption line present in the
        spectrum for an element (e.g., \ion{O}{1}), and that absorption line
        is blended with a comparably strong transition from another element
        (e.g., \ion{Ni}{1}), then the measured abundances of \ion{O}{1} and
        \ion{Ni}{2} will be (positively) correlated.
        This correlation may be difficult to discern from an \emph{intrinsic}
        correlation between the two elements.
\end{enumerate}
\end{comment}
